% !TEX root =  ../Dissertation.tex

\chapter{Testing}


Testing ensures that the tools behave correctly, it also allows for better
maintainability as any changes can be automatically checked for issues. For
Agda Tree, there are unit tests for each query. Giving some guarantee that the
queries are working as expected and that any future changes still return the
same results. These tests were also timed, to measure the performance of the
queries, while some will vary in performance depending on their input it gives
a good estimate of their performance.


For Agda Comp, testing focused on validating the correctness and safety of its
compilation strategies. The tests ensured that all modules in a project were
compiled, no modules were skipped, and no module was compiled simultaneously
with one of its dependencies. Additionally, the time required to generate the
compilation order was measured but negligible compared to the overall project
compilation time.


\section{Agda Tree Unit Tests}


Each query and the options that the queries can take are unit tested. These
test use the TypeTopology definition and module dependency graph. While testing
every combination of input for this graph and checking the output isn't
possible, the test instead evaluates one example of that query. For example, to
test the dependencies query the definition \texttt{ InfinitePigeon.Addition.
n-plus-zero-equals-n} is passed in, and the output is
checked given an expected response. This is done for each query, along with
each of their options. So, the dependencies query there is also a unit test
for the indirect option.

\section{Agda Tree Performance} \label{sub:agda tree performance}

The performance of the queries has been measured, although, this will be highly
dependent of the size of the graph and the Agda project. In this case
TypeTopology was used, it is a large project with about 50,000 definitions.
This gives a good representation of how long queries will take with most
projects.

Most queries are completed in under 20ms (milliseconds), except cycles queries,
the indirect uses query and path queries. The cycles query takes about 622ms to
be completed, and the indirect uses takes about 3804ms to be completed. These
queries recursively call and traverse the whole graph multiple times, so this
is expected. The path between two definitions queries can vary depending on the
definitions, due to cycles and size of the graph the time to complete this
query can go from less than a millisecond to impossible.

Lastly, the create tree query takes the longest time to be completed. As it has
to compile the entire Agda project, then parse all the s-expression files into
a graph. For TypeTopology this can take 8 minutes or more, although, the
command only runs once, after which, the graph is re-used.

\section{Agda Comp Strategy Validation}

For a compilation strategy to be valid it must be correct, that is it compiles
all the modules in the project. It must also be safe, so a module can't be
compiled at the same time as one of its dependencies or itself. These two
properties are checked for the level strategy and the disjoint level strategy
described in \cref{sub:design level strategy}. The correctness check is done by
adding each module and its dependencies to a set, if this set is the same as
the set of all the modules in the dependency graph then it is correct as all
modules are compiled eventually. The safety check is done by going through each
step of the compilation order, if there are modules that are compiled in
parallel then the dependencies are checked to be distinct. If so, they are
removed from the graph and the next step is checked. By the end if all modules
compiled in parallel had distinct dependencies then the overall compilation is
safe.

The performance of Agda Comp is highly dependent on the Agda project, and will
be assessed on \cref{sub:eval comp strat} as the purpose of the tool is to
speed up compilation. The time to create the level and level B tests is
1-millisecond and level disjoint takes about 50 milliseconds. This time is
negligible compared to the 5 minutes it normally takes TypeTopology to be
compiled.

\section{Conclusion}

Agda Tree unit tests each query, checking if a certain input returns the
correct output. Improving maintainability and stability of the code base. The
tests are timed, with most queries being instant except for cycles, path
between, path to leaf and indirect uses which can take from half a second to
indefinite depending on the input.  

Agda Comp was tested on the validity of the strategies, whether the strategies
were correct and safe. The Agda type checker doesn't give any perceivable error
with unsafe or incomplete compilation, so it is critical to give a guarantee of
a well done compilation. The time to create the compilation order was tested,
but it is negligible compare to compilation time taking at most 50
milliseconds.

% test.test_definition.TestDefinitionQueries.test_create_tree: 0.000
% .test.test_definition.TestDefinitionQueries.test_cycles: 0.622
% .test.test_definition.TestDefinitionQueries.test_dependencies: 0.000
% .test.test_definition.TestDefinitionQueries.test_dependencies_indirect: 0.000
% .test.test_definition.TestDefinitionQueries.test_dependents: 0.000
% .test.test_definition.TestDefinitionQueries.test_dependents_indirect: 0.000
% .test.test_definition.TestDefinitionQueries.test_find: 0.019
% .test.test_definition.TestDefinitionQueries.test_find_name: 0.018
% .test.test_definition.TestDefinitionQueries.test_leafs: 0.009
% .test.test_definition.TestDefinitionQueries.test_module_dependencies: 0.000
% .test.test_definition.TestDefinitionQueries.test_module_dependencies_indirect: 0.000
% .test.test_definition.TestDefinitionQueries.test_module_dependents: 0.000
% .test.test_definition.TestDefinitionQueries.test_module_dependents_indirect: 0.000
% .test.test_definition.TestDefinitionQueries.test_module_path_to_leaf: 0.009
% .test.test_definition.TestDefinitionQueries.test_nodes: 0.002
% .Node count: 53643
% test.test_definition.TestDefinitionQueries.test_nodes_count: 0.000
% .test.test_definition.TestDefinitionQueries.test_path_between: 0.000
% .test.test_definition.TestDefinitionQueries.test_path_to_leaf: 0.008
% .test.test_definition.TestDefinitionQueries.test_roots: 0.008
% .test.test_definition.TestDefinitionQueries.test_type: 0.000
% .test.test_definition.TestDefinitionQueries.test_uses: 0.015
% .test.test_definition.TestDefinitionQueries.test_uses_definition: 0.000
% .test.test_definition.TestDefinitionQueries.test_uses_indirect: 3.804
% ..........Node count: 807
% ......
% ----------------------------------------------------------------------
% Ran 38 tests in 4.517s
%
% OK

% As well as documenting system testing, this section should also describe any
% unit testing or integration testing performed. If you are not familiar with
% unit, integration or system testing then it would be a good idea to investigate
% these notions and consider about how they relate to your project. This section
% might also detail any performance, reliability or usability testing performed,
% with quantification, i.e., numeric measurements, being used wherever possible.
% All those points are systems focused through. If you’re doing something that’s
% research focused or more of a social / analytical study then you need to think
% about how you’ll measure success.

% \begin{itemize}
% \item The unit testing of agda tree definito nad module grpah, how it was done,
%   explain 
% \item The testing of the strategies in agda comp 
% \item Mention how quickly the queries run except for finding paths 
% \item Mention how long it takes to create a tree 
% \item Mention how the CLI is created directly from the query, so it is
%   unnecesary to do integration testing.
% \item Measure compilation time 
% \item Measure time to build graph 
% \item Measure time to make queries 
% \end{itemize}
